{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stored information\n",
    "actual_folder_destination = \"TODO - replace with your actual folder's ID\"\n",
    "test_folder_destination = \"TODO - replace with your test folder's ID. this is what is currently being used in the script\"\n",
    "client_secret_path = \"TODO - replace with the path to your client secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate and create Google Drive service\n",
    "def authenticate_google_drive():\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    creds = None\n",
    "    \n",
    "    # load previously saved credentials\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "\n",
    "    # if no valid credentials, authenticate user\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                client_secret_path, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        # save credentials\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# upload a file to Google Drive\n",
    "def upload_to_drive(service, file_path, parent_folder_id, mime_type):\n",
    "    file_metadata = {'name': os.path.basename(file_path), 'parents': [parent_folder_id]}\n",
    "    media = MediaFileUpload(file_path, mimetype=mime_type)\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    return file.get('id')\n",
    "\n",
    "# upload a folder to Google Drive\n",
    "def upload_folder_to_drive(service, folder_path, parent_folder_id):\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    folder_metadata = {\n",
    "        'name': folder_name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder',\n",
    "        'parents': [parent_folder_id]\n",
    "    }\n",
    "    folder = service.files().create(body=folder_metadata, fields='id').execute()\n",
    "    folder_id = folder.get('id')\n",
    "\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            mime_type = 'application/vnd.google.colaboratory' if file.endswith('.ipynb') else None\n",
    "            if mime_type or file.endswith('.py'):\n",
    "                new_file_path = convert_to_colab_format(file_path)\n",
    "                upload_to_drive(service, new_file_path, folder_id, mime_type)\n",
    "            else:\n",
    "                upload_to_drive(service, file_path, folder_id, None)\n",
    "\n",
    "    return folder_id\n",
    "\n",
    "# convert .ipynb or .py files to Colab-compatible format\n",
    "def convert_to_colab_format(file_path):\n",
    "    if file_path.endswith('.ipynb') or file_path.endswith('.py'):\n",
    "        return file_path  # no conversion needed\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load DataFrame with 'folder URL' and 'repo URL' columns\n",
    "    df = pd.read_csv(\"download_git_TEST.csv\")\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # temporary directory for cloning repositories\n",
    "    temp_dir = 'temp'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Google Drive parent folder ID\n",
    "    parent_folder_id = test_folder_destination  \n",
    "    service = authenticate_google_drive()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        print()\n",
    "        folder_url = row.get('folder URL', None)\n",
    "        print(\"folder_url:\", folder_url)\n",
    "        repo_url = row.get('repo URL', None)\n",
    "\n",
    "        try:\n",
    "            if isinstance(folder_url, str):\n",
    "                # if folder URL is provided\n",
    "                df_copy['Resource'] = folder_url+'||'+df['file name']\n",
    "                print(f\"Processing folder URL: {folder_url}\")\n",
    "                if '/tree/' in folder_url:\n",
    "                    repo_base_url, folder_path = folder_url.split('/tree/', 1)\n",
    "                    folder_subpath = folder_path.split('/', 1)[-1] if '/' in folder_path else folder_path\n",
    "                else:\n",
    "                    print(f\"Invalid folder URL format: {folder_url}. Skipping...\")\n",
    "                    continue\n",
    "                repo_url = repo_base_url\n",
    "            elif isinstance(repo_url, str):\n",
    "                # if repository URL is provided\n",
    "                print(f\"Processing repository URL: {repo_url}\")\n",
    "                folder_subpath = \"\"  # process entire repository\n",
    "            else:\n",
    "                print(f\"Invalid row: no URL provided. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # clone repository\n",
    "            repo_name = os.path.basename(repo_url)\n",
    "            local_repo_path = os.path.join(temp_dir, repo_name)\n",
    "            print(f\"Cloning {repo_url} to {local_repo_path}...\")\n",
    "            clone_result = os.system(f'git clone {repo_url} {local_repo_path}')\n",
    "\n",
    "            if clone_result != 0:\n",
    "                print(f\"Failed to clone repository: {repo_url}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # verify the folder path\n",
    "            if folder_subpath:\n",
    "                local_folder_path = os.path.join(local_repo_path, folder_subpath)\n",
    "                if not os.path.exists(local_folder_path):\n",
    "                    print(f\"Subfolder {folder_subpath} not found in {repo_url}. Skipping...\")\n",
    "                    continue\n",
    "            else:\n",
    "                local_folder_path = local_repo_path\n",
    "\n",
    "            print(f\"Uploading folder: {local_folder_path} to Google Drive...\")\n",
    "            uploaded_folder_id = upload_folder_to_drive(service, local_folder_path, parent_folder_id)\n",
    "            print(f\"Uploaded folder ID: {uploaded_folder_id}\")\n",
    "\n",
    "        except HttpError as e:\n",
    "            print(f\"Google Drive API error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # remove cloned repository\n",
    "            if os.path.exists(local_repo_path):\n",
    "                shutil.rmtree(local_repo_path)\n",
    "\n",
    "    # remove temporary directory\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "    # reorder columns and save to new CSV\n",
    "    df_reordered = df_copy.loc[:, ['Resource', 'Computing Topics', 'Context Topics', 'Libraries Used', 'Language', 'Level', 'Last Updated', 'Source Institution']]\n",
    "    df_reordered.to_csv(\"updated_resources_GIT_test.csv\", index=False)\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "folder_url: https://github.com/ds-modules/LINGUIS-110/tree/master/FormantsUpdated\n",
      "Processing folder URL: https://github.com/ds-modules/LINGUIS-110/tree/master/FormantsUpdated\n",
      "Cloning https://github.com/ds-modules/LINGUIS-110 to temp/LINGUIS-110...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/LINGUIS-110'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/LINGUIS-110/FormantsUpdated to Google Drive...\n",
      "Uploaded folder ID: 1AS2qGVgDfUrWN8VCYdBjRMJFXjic3V8e\n",
      "\n",
      "folder_url: https://github.com/ds-modules/LINGUIS-110/tree/master/VOT\n",
      "Processing folder URL: https://github.com/ds-modules/LINGUIS-110/tree/master/VOT\n",
      "Cloning https://github.com/ds-modules/LINGUIS-110 to temp/LINGUIS-110...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/LINGUIS-110'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/LINGUIS-110/VOT to Google Drive...\n",
      "Uploaded folder ID: 1CUMQaVW7HQlrJz0EQKy9TsFJCLf9KY3i\n",
      "\n",
      "folder_url: nan\n",
      "Processing repository URL: https://github.com/ds-modules/SOC-130AC\n",
      "Cloning https://github.com/ds-modules/SOC-130AC to temp/SOC-130AC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/SOC-130AC'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/SOC-130AC to Google Drive...\n",
      "Uploaded folder ID: 13ocTpuqL6CYUFHTCFZP7x_G8VZiN4OWc\n",
      "\n",
      "folder_url: https://github.com/ds-modules/ECON-101B/tree/master/Previous/Problem%20Set%201\n",
      "Processing folder URL: https://github.com/ds-modules/ECON-101B/tree/master/Previous/Problem%20Set%201\n",
      "Cloning https://github.com/ds-modules/ECON-101B to temp/ECON-101B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/ECON-101B'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder Previous/Problem%20Set%201 not found in https://github.com/ds-modules/ECON-101B. Skipping...\n",
      "\n",
      "folder_url: https://github.com/ds-modules/ECON-101B/tree/master/Problem%20Set%203\n",
      "Processing folder URL: https://github.com/ds-modules/ECON-101B/tree/master/Problem%20Set%203\n",
      "Cloning https://github.com/ds-modules/ECON-101B to temp/ECON-101B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/ECON-101B'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder Problem%20Set%203 not found in https://github.com/ds-modules/ECON-101B. Skipping...\n",
      "\n",
      "folder_url: nan\n",
      "Processing repository URL: https://github.com/ds-modules/XENGLIS-31AC\n",
      "Cloning https://github.com/ds-modules/XENGLIS-31AC to temp/XENGLIS-31AC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/XENGLIS-31AC'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/XENGLIS-31AC to Google Drive...\n",
      "Uploaded folder ID: 18D7fjMdPLF--rQARRFp9reMUUWlVU508\n",
      "\n",
      "folder_url: https://github.com/ds-modules/PSYCH-167AC/blob/master/01-Intro-to-Importing-Data-Tables-Graphs.ipynb\n",
      "Processing folder URL: https://github.com/ds-modules/PSYCH-167AC/blob/master/01-Intro-to-Importing-Data-Tables-Graphs.ipynb\n",
      "Invalid folder URL format: https://github.com/ds-modules/PSYCH-167AC/blob/master/01-Intro-to-Importing-Data-Tables-Graphs.ipynb. Skipping...\n",
      "\n",
      "folder_url: https://github.com/ds-modules/PSYCH-167AC/blob/master/02-Correlation-Regression.ipynb\n",
      "Processing folder URL: https://github.com/ds-modules/PSYCH-167AC/blob/master/02-Correlation-Regression.ipynb\n",
      "Invalid folder URL format: https://github.com/ds-modules/PSYCH-167AC/blob/master/02-Correlation-Regression.ipynb. Skipping...\n",
      "\n",
      "folder_url: nan\n",
      "Processing repository URL: https://github.com/ds-modules/PSYCH-167AC/tree/master\n",
      "Cloning https://github.com/ds-modules/PSYCH-167AC/tree/master to temp/master...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/master'...\n",
      "fatal: repository 'https://github.com/ds-modules/PSYCH-167AC/tree/master/' not found\n",
      "Cloning into 'temp/XRHETOR-R1A'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to clone repository: https://github.com/ds-modules/PSYCH-167AC/tree/master. Skipping...\n",
      "\n",
      "folder_url: https://github.com/ds-modules/XRHETOR-R1A/tree/master/01%20-%20Data%20Science%20in%20xRhetoric%20Intro\n",
      "Processing folder URL: https://github.com/ds-modules/XRHETOR-R1A/tree/master/01%20-%20Data%20Science%20in%20xRhetoric%20Intro\n",
      "Cloning https://github.com/ds-modules/XRHETOR-R1A to temp/XRHETOR-R1A...\n",
      "Subfolder 01%20-%20Data%20Science%20in%20xRhetoric%20Intro not found in https://github.com/ds-modules/XRHETOR-R1A. Skipping...\n",
      "\n",
      "folder_url: https://github.com/ds-modules/XRHETOR-R1A/tree/master/02-Moral-Foundations-Analysis\n",
      "Processing folder URL: https://github.com/ds-modules/XRHETOR-R1A/tree/master/02-Moral-Foundations-Analysis\n",
      "Cloning https://github.com/ds-modules/XRHETOR-R1A to temp/XRHETOR-R1A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/XRHETOR-R1A'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/XRHETOR-R1A/02-Moral-Foundations-Analysis to Google Drive...\n",
      "Uploaded folder ID: 1LjOidJcxK12UiSJen-0YlNyoiyiqtE8h\n",
      "\n",
      "folder_url: https://github.com/ds-modules/XRHETOR-R1A/tree/master/03-Rhetoric-of-Data\n",
      "Processing folder URL: https://github.com/ds-modules/XRHETOR-R1A/tree/master/03-Rhetoric-of-Data\n",
      "Cloning https://github.com/ds-modules/XRHETOR-R1A to temp/XRHETOR-R1A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/XRHETOR-R1A'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/XRHETOR-R1A/03-Rhetoric-of-Data to Google Drive...\n",
      "Uploaded folder ID: 1uYKyZde51-3sTyTdfBXfCpKnG92-fsNO\n",
      "\n",
      "folder_url: nan\n",
      "Processing repository URL: https://github.com/ds-modules/CUNEIF-102A/tree/master\n",
      "Cloning https://github.com/ds-modules/CUNEIF-102A/tree/master to temp/master...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/master'...\n",
      "fatal: repository 'https://github.com/ds-modules/CUNEIF-102A/tree/master/' not found\n",
      "Cloning into 'temp/master'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to clone repository: https://github.com/ds-modules/CUNEIF-102A/tree/master. Skipping...\n",
      "\n",
      "folder_url: nan\n",
      "Processing repository URL: https://github.com/ds-modules/CUNEIF-102A/tree/master\n",
      "Cloning https://github.com/ds-modules/CUNEIF-102A/tree/master to temp/master...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: repository 'https://github.com/ds-modules/CUNEIF-102A/tree/master/' not found\n",
      "Cloning into 'temp/LEGALST-190'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to clone repository: https://github.com/ds-modules/CUNEIF-102A/tree/master. Skipping...\n",
      "\n",
      "folder_url: https://github.com/ds-modules/LEGALST-190/tree/master/labs/3-22\n",
      "Processing folder URL: https://github.com/ds-modules/LEGALST-190/tree/master/labs/3-22\n",
      "Cloning https://github.com/ds-modules/LEGALST-190 to temp/LEGALST-190...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating files: 100% (502/502), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading folder: temp/LEGALST-190/labs/3-22 to Google Drive...\n",
      "Uploaded folder ID: 1AKkLgz-YZa7DSSvyojSQ3iWXFcUBQV8b\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
